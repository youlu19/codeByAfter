### 增量式

- 爬虫应用场景分类

  - 通用爬虫
  - 聚焦爬虫
  - 功能爬虫
  - 分布式爬虫
  - 增量式：
    - 用来监测网站数据更新的情况（爬取网站最新更新出来的数据）。
    - 只是一种程序设计的思路，使用什么技术都是可以实现的。
    - 核心：
      - 去重。
        - 使用一个记录表来实现数据的去重：
          - 记录表：存储爬取过的数据的记录
          - 如何构建和设计一个记录表：
            - 记录表需要具备的特性：
              - 去重
              - 需要持久保存的
            - 方案1：使用Python的set集合充当记录表？
              - 不可以的！因为set集合无法实现持久化存储
            - 方案2：使用redis的set集合充当记录表？
              - 可以的，因为redis的set既可以实现去重又可以进行数据的持久化存储。

  

  - ```python
    import scrapy
    import redis
    from ..items import Zlsdemo2ProItem
    class JianliSpider(scrapy.Spider):
        name = 'jianli'
        # allowed_domains = ['www.xxx.com']
        start_urls = ['https://sc.chinaz.com/jianli/free.html']
        conn = redis.Redis(host='127.0.0.1',port=6379)
        def parse(self, response):
            div_list = response.xpath('//*[@id="container"]/div')
            for div in div_list:
                title = div.xpath('./p/a/text()').extract_first()
                #充当数据指纹
                detail_url = 'https:'+div.xpath('./p/a/@href').extract_first()
                ex = self.conn.sadd('data_id',detail_url)
                item = Zlsdemo2ProItem()
                item['title'] = title
                if ex == 1:
                    print('有最新数据的更新，正在采集......')
                    yield scrapy.Request(url=detail_url,callback=self.parse_detail,meta={'item':item})
                else:
                    print('暂无数据更新！')
    
        def parse_detail(self,response):
            item = response.meta['item']
            download_url = response.xpath('//*[@id="down"]/div[2]/ul/li[1]/a/@href').extract_first()
            item['download_url'] = download_url
    
            yield item
    ```

