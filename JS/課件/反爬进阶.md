### 防盗链

- 现在很多网站启用了防盗链反爬，防止服务器上的资源被人恶意盗取。什么是防盗链呢？

  -  从HTTP协议说起，在HTTP协议中，有一个表头字段：referer，采用URL的格式来表示从哪一个链接跳转到当前网页的。通俗理解就是：客户端的请求具体从哪里来，服务器可以通过referer进行溯源。一旦检测来源不是网页所规定的，立即进行阻止或者返回指定的页面。

- 案例：抓取微博图片，url：http://blog.sina.com.cn/lm/pic/，将页面中某一组系列详情页的图片进行抓取保存，比如三里屯时尚女郎：http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1

  - 注意：

    - 1.在解析图片地址的时候，定位src的属性值，返回的内容和开发工具Element中看到的不一样，通过network查看网页源码发现需要解析real_src的值。

    - 2.直接请求real_src请求到的图片不显示，加上Refere请求头即可

      - 哪里找Refere：抓包工具定位到某一张图片数据包，在其requests headers中获取

    - ```python
      import requests
      from lxml import etree
      headers = {
          'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',
          'Referer':'https://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1'
      }
      url = 'https://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1'
      page_text = requests.get(url,headers=headers).text
      
      tree = etree.HTML(page_text)
      a_list = tree.xpath('//*[@id="sina_keyword_ad_area2"]/div/a')
      for a in a_list:
          img_src = a.xpath('./img/@real_src')[0]
          img_data = requests.get(img_src,headers=headers).content
          with open('123.jpg','wb') as fp:
              fp.write(img_data)
          break
      ```

### 代理（重要）

- 什么是代理
  - 代理服务器
- 代理服务器的作用    
  - 就是用来转发请求和响应		

- 在爬虫中为何需要使用代理？  

  - 有些时候，需要对网站服务器发起高频的请求，网站的服务器会检测到这样的异常现象，则会讲请求对应机器的ip地址加入黑名单，则该ip再次发起的请求，网站服务器就不在受理，则我们就无法再次爬取该网站的数据。
  - 使用代理后，网站服务器接收到的请求，最终是由代理服务器发起，网站服务器通过请求获取的ip就是代理服务器的ip，并不是我们客户端本身的ip。

- 代理的匿名度

  - 透明：网站的服务器知道你使用了代理，也知道你的真实ip
  - 匿名：网站服务器知道你使用了代理，但是无法获知你真实的ip
  - 高匿：网站服务器不知道你使用了代理，也不知道你的真实ip（推荐）

- 代理的类型（重要）

  - http：该类型的代理服务器只可以转发http协议的请求
  - https：可以转发https协议的请求  

- 如何获取代理?

  - 携趣代理：https://www.xiequ.cn/index.html?f301de7f

- 如何使用代理？

  - 测试：访问如下网址，返回自己本机ip

  - ```python
    import requests
    from lxml import etree
    headers = {
        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36',
    }
    url = 'http://www.cip.cc/'
    
    page_text = requests.get(url,headers=headers).text
    tree = etree.HTML(page_text)
    text = tree.xpath('/html/body/div/div/div[3]/pre/text()')[0]
    print(text.split('\n')[0])
    ```

  - 使用代理发起请求，查看是否可以返回代理服务器的ip

  - ```python
    import requests
    from lxml import etree
    headers = {
        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36',
    }
    url = 'http://www.cip.cc/'
    
    page_text = requests.get(url,headers=headers,proxies={'http':'121.234.12.62:4246'}).text
    tree = etree.HTML(page_text)
    text = tree.xpath('/html/body/div/div/div[3]/pre/text()')[0]
    print(text.split('\n')[0])
    ```

    代理池

    https://wz.sun0769.com/political/index/politicsNewest?id=1

    ```python
    import requests
    from lxml import etree
    import random
    headers = {
        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',
    }
    def get_proxy_pool():
        p_url = '代理提取的url'
        page_text = requests.get(p_url).text
        proxy_list = page_text.split('\r\n')
        return proxy_list
    proxy_list = get_proxy_pool() #获取了代理池（列表）
    
    for page in range(1,100):
        url = 'https://wz.sun0769.com/political/index/politicsNewest?id=1&page=%d'%page
        page_text = requests.get(url,headers=headers,proxies={'https':random.choice(proxy_list)}).text
        tree = etree.HTML(page_text)
        ret = tree.xpath('/html/body/div[2]/div[3]/ul[2]/li[1]/span[3]/a/text()')[0]
        print(ret)
    
    ```
    
    

